03/13/2025 21:48:12 - INFO - __main__ - ***** Training arguments *****
03/13/2025 21:48:12 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', dataset='cifar10', data_dir='./data', image_size=128, batch_size=4, num_workers=4, num_classes=10, DEBUG=False, wandb_key='b6dff554fc854aea97af8dccb735c241a19a6615', project_name='dl-hw5', run_name='exp-13-test', output_dir='experiments', num_epochs=2, learning_rate=0.0001, weight_decay=0.0001, grad_clip=1.0, seed=42, mixed_precision='none', num_train_timesteps=100, num_inference_steps=50, beta_start=0.0002, beta_end=0.02, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, unet_in_size=128, unet_in_ch=3, unet_ch=128, unet_ch_mult=[1, 2, 2, 4], unet_attn=[2, 3], unet_num_res_blocks=2, unet_dropout=0.0, latent_ddpm=False, use_cfg=False, cfg_guidance_scale=2.0, use_ddim=False, ckpt=None, predictor_type='epsilon', distributed=False, world_size=1, rank=0, local_rank=0, device='cuda', total_batch_size=4, max_train_steps=25000)
03/13/2025 21:48:12 - INFO - __main__ - ***** Running training *****
03/13/2025 21:48:12 - INFO - __main__ -   Num examples = 50000
03/13/2025 21:48:12 - INFO - __main__ -   Num Epochs = 2
03/13/2025 21:48:12 - INFO - __main__ -   Instantaneous batch size per device = 4
03/13/2025 21:48:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
03/13/2025 21:48:12 - INFO - __main__ -   Total optimization steps per epoch 12500
03/13/2025 21:48:12 - INFO - __main__ -   Total optimization steps = 25000
  0%|                                                            | 0/25000 [00:00<?, ?it/s]03/13/2025 21:48:12 - INFO - __main__ - Epoch 1/2
Exception ignored in: <function _releaseLock at 0x787491592320>
Traceback (most recent call last):
  File "/usr/lib/python3.10/logging/__init__.py", line 233, in _releaseLock
    _lock.release()
KeyboardInterrupt:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1132, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.10/queue.py", line 179, in get
    raise Empty
_queue.Empty

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/hw5/train.py", line 541, in <module>
    main()
  File "/root/hw5/train.py", line 429, in main
    for step, (images, labels) in enumerate(train_loader):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1284, in _get_data
    success, data = self._try_get_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1145, in _try_get_data
    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e
RuntimeError: DataLoader worker (pid(s) 8532, 8580) exited unexpectedly

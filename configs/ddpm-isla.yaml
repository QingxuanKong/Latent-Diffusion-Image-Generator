seed: 42

DEBUG: False
output_dir: /workspace/experiments/

# dataset
dataset: imagenet100
data_dir: /root/hw5/data
val_data_dir: /root/hw5/data/imagenet100_128x128/validation
subset: 1.0
image_size: 64
num_classes: 100

# training
batch_size: 32
num_workers: 4
num_epochs: 50

# optimizer
max_epochs: 50
learning_rate: 2e-4
weight_decay: 1e-4

# Isla wandb
wandb_username: islakong-carnegie-mellon-university
wandb_key: b6dff554fc854aea97af8dccb735c241a19a6615
project_name: dl-hw5
run_name: ddpm(cosine)-vae-cfg

# resume wandb
resume: True
wandb_resume_id: "t0yxlvis"
# resume_checkpoint_path: "/root/hw5/experiments/exp-11-ddim-cfg/checkpoints/checkpoint_epoch_4.pth"

# # Ivy wandb
# wandb_key: dbcb5b22a7512074ad91148adc5794d1955289ad
# project_name: IDL-hw5-Ivy
# run_name: ddim-cfg-epoch5-Baseline

# # Bryan wandb
# wandb_key: 2e236a3f67726acb3dd528ffcda489a4f92f5457
# project_name: dl-hw5
# run_name: ddpm-epoch5-Baseline-Bryan-run1

# # unet
# unet_in_size: 64
# unet_in_ch: 3
# unet_ch: 128
# unet_ch_mult: [1, 2, 2, 4]
# unet_attn: [2, 3]
# unet_num_res_blocks: 2
# unet_dropout: 0.0
# use_adagn_resblock: False
# use_transformer_bottleneck: False
# transformer_depth: 1
# transformer_num_heads: 8

# vae unet
unet_in_size: 16
unet_in_ch: 3
unet_ch: 128
unet_ch_mult: [1, 2, 2, 4]
unet_attn: [2, 3] # -> [1, 2]
unet_num_res_blocks: 2
unet_dropout: 0.0
use_adagn_resblock: False
use_transformer_bottleneck: False
transformer_depth: 1
transformer_num_heads: 8

vae_config:
  double_z: True
  z_channels: 3
  embed_dim: 3
  resolution: 256
  in_channels: 3
  out_ch: 3
  ch: 128
  ch_mult: [1, 2, 4]
  num_res_blocks: 2


# ddpm
num_train_timesteps: 1000
num_inference_steps: 1000
beta_start: 0.0002
beta_end: 0.02
beta_schedule: cosine
variance_type: fixed_small
predictor_type: epsilon

#latent
latent_ddpm: True

# cfg
use_cfg: True
cfg_guidance_scale: 3.0
cond_drop_rate: 0.1

# ddim
use_ddim: False

# checkpoint
keep_last_n: 1 # including the last one
keep_last_model: True
keep_best_model: False

#evaluation during training
eval_during_train: False
eval_every_n_epoch: 5 # it takes 10 min to generate 500 images for evaluation each time
eval_samples: 500 # 500
eval_classes: 50 # 50

# inference
inference_samples: 5000
#

seed: 42

# Isla dataset
# data_dir: /jet/home/ikong/hw5/data/
# val_data_dir: /jet/home/ikong/hw5/data/imagenet100_128x128/validation

# Ivy Dataset
data_dir: /jet/home/ygao8/11785-hw5/data
val_data_dir: /jet/home/ygao8/11785-hw5/data/imagenet100_128x128/validation

# Dataset
dataset: imagenet100
subset: 1
image_size: 64
num_classes: 100
output_dir: experiments

# training
batch_size: 32
num_workers: 4
num_epochs: 5

# optimizer
learning_rate: 2e-4
weight_decay: 1e-4

# Isla wandb
# wandb_key: b6dff554fc854aea97af8dccb735c241a19a6615
# project_name: dl-hw5
# run_name: ddim-timestep(1000,100)-epoch(5)

# Ivy wandb
wandb_key: dbcb5b22a7512074ad91148adc5794d1955289ad
project_name: IDL-hw5-Ivy
run_name: ddim-cfg-epoch5-Baseline
resume_checkpoint_path: /jet/home/ygao8/11785-hw5/experiments/exp-4-ddpm-cfg-epoch60-Baseline/checkpoints/last_model.pth
resume: True
wandb_resume_id: 0n7x860l

# # Bryan wandb
# wandb_key: 2e236a3f67726acb3dd528ffcda489a4f92f5457
# project_name: dl-hw5
# run_name: ddpm-epoch5-Baseline-Bryan-run1

# unet
unet_in_size: 64
unet_in_ch: 3
unet_ch: 128
unet_ch_mult: [1, 2, 2, 4]
unet_attn: [2, 3]
unet_num_res_blocks: 2
unet_dropout: 0.0

# ddpm
num_train_timesteps: 1000
num_inference_steps: 1000
beta_start: 0.0002
beta_end: 0.02
beta_schedule: linear
variance_type: fixed_small
predictor_type: epsilon

#latent
latent_ddpm: False

# cfg
use_cfg: True
cfg_guidance_scale: 3.0
cond_drop_rate: 0.1

# ddim
use_ddim: False

#evaluation during training
eval_during_train: True
eval_every_n_epoch: 1 # it takes 10 min to generate 500 images for evaluation each time
eval_samples: 500 # 500
eval_classes: 50 # 50

